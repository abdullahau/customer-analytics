{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDNOW = (\n",
    "    pl.scan_csv(source='data/CDNOW/CDNOW_sample.csv',\n",
    "                has_header=False,\n",
    "                separator=',',\n",
    "                schema={'CustID': pl.Int32,\n",
    "                        'ID': pl.Int32,\n",
    "                        'Date': pl.String,\n",
    "                        'Quant': pl.Int16,\n",
    "                        'Spend': pl.Float64})\n",
    "    .with_columns(pl.col('Date').str.to_date(\"%Y%m%d\"))\n",
    "    .with_columns((pl.col('Date') - pl.date(1996,12,31)).dt.total_days().cast(pl.UInt16).alias('PurchDay'))\n",
    "    .with_columns((pl.col('Spend')*100).round(0).cast(pl.Int64).alias('Spend Scaled'))\n",
    "    .group_by('ID', 'Date')\n",
    "    .agg(pl.col('*').exclude('PurchDay').sum(), pl.col('PurchDay').max())\n",
    "    .sort('ID', 'Date')\n",
    "    .with_columns((pl.col(\"ID\").cum_count().over(\"ID\") - 1).cast(pl.UInt16).alias(\"DoR\"))      \n",
    "    .drop('CustID')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "calwk = 273 # 39 week calibration period\n",
    "\n",
    "# The number of repeat transactions made by each customer in each period\n",
    "freq_x = (\n",
    "    CDNOW\n",
    "    .group_by('ID', maintain_order=True)\n",
    "    .agg(\n",
    "        pl.col('PurchDay')\n",
    "        .filter((pl.col('PurchDay') <= calwk) & (pl.col('DoR') > 0))\n",
    "        .count()\n",
    "        .alias('P1X'), # Period 1: Calibration Period\n",
    "\n",
    "        pl.col('PurchDay')\n",
    "        .filter((pl.col('PurchDay') > calwk) & (pl.col('DoR') > 0))\n",
    "        .count()\n",
    "        .alias('P2X')  # Period 2: Longitudinal Holdout Period      \n",
    "    )\n",
    ")\n",
    "\n",
    "# The number of CDs purchased and total spend across these repeat transactions\n",
    "pSpendQuant = (\n",
    "    CDNOW\n",
    "    .join(freq_x, on='ID', how='left')\n",
    "    .group_by('ID', maintain_order=True)\n",
    "    .agg(\n",
    "        \n",
    "        pl.col('Spend Scaled')\n",
    "        .filter((pl.col('DoR') > 0) & (pl.col('DoR') <= pl.col('P1X')) & (pl.col('P1X') != 0))\n",
    "        .sum()\n",
    "        .alias('P1X Spend'),\n",
    "        \n",
    "        pl.col('Quant')\n",
    "        .filter((pl.col('DoR') > 0) & (pl.col('DoR') <= pl.col('P1X')) & (pl.col('P1X') != 0))\n",
    "        .sum()\n",
    "        .alias('P1X Quant'),        \n",
    "        \n",
    "        pl.col('Spend Scaled')\n",
    "        .filter((pl.col('DoR') > 0) & (pl.col('DoR') > pl.col('P1X')))\n",
    "        .sum()\n",
    "        .alias('P2X Spend'),\n",
    "        \n",
    "        pl.col('Quant')\n",
    "        .filter((pl.col('DoR') > 0) & (pl.col('DoR') > pl.col('P1X')))\n",
    "        .sum()\n",
    "        .alias('P2X Quant')                \n",
    "    )\n",
    ")\n",
    "\n",
    "# The average spend per repeat transaction\n",
    "m_x = (\n",
    "    pSpendQuant\n",
    "    .join(freq_x, on='ID', how='left')\n",
    "    .with_columns(\n",
    "        (pl.col('P1X Spend') / pl.col('P1X')).alias('m_x_calib'),\n",
    "        (pl.col('P2X Spend') / pl.col('P2X')).alias('m_x_valid')\n",
    "    ).fill_nan(0)\n",
    ")\n",
    "\n",
    "# time of last calibration period repeat purchase (in weeks) - Recency\n",
    "ttlrp = (\n",
    "    CDNOW\n",
    "    .join(freq_x, on='ID', how='left')\n",
    "    .with_columns(\n",
    "        pl.col('PurchDay').filter(pl.col('DoR') == 0)\n",
    "        .first()\n",
    "        .over('ID')\n",
    "        .alias('Trial Day')\n",
    "    )\n",
    "    .group_by('ID', maintain_order=True)\n",
    "    .agg(\n",
    "        pl.col('PurchDay', 'Trial Day')\n",
    "        .filter(pl.col('DoR') <= pl.col('P1X'))\n",
    "        .max()\n",
    "        # .alias('LastPurch')\n",
    "    )\n",
    "    .with_columns(\n",
    "        # effective calibration period (in weeks)\n",
    "        ((pl.col('PurchDay') - pl.col('Trial Day')) / 7).alias('t_x'), # Time to Last Repeat Purchase - Recency\n",
    "        ((calwk - pl.col('Trial Day'))/7).alias('T')\n",
    "    )\n",
    "    .drop('PurchDay', 'Trial Day')\n",
    ")\n",
    "\n",
    "rfm_data = (\n",
    "    m_x\n",
    "    .join(other=ttlrp, on=\"ID\", how=\"left\")\n",
    "    .rename({'P1X': 'x'})\n",
    "    .select('ID', 'x', 't_x', 'T')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgnbd_est(rfm_data, guess={'r': 0.1, 'alpha': 0.1, 'a': 0.1, 'b':0.1}):\n",
    "    \n",
    "    def log_likelihood(x):\n",
    "        r, alpha, a, b = x\n",
    "        return -(\n",
    "            rfm_data\n",
    "            .with_columns(\n",
    "                (gammaln(pl.col('x') + r) - gammaln(r) + r * np.log(alpha)).alias('ln(A_1)'),\n",
    "                (gammaln(a + b) + gammaln(b + pl.col('x')) - gammaln(b) - gammaln(a + b + pl.col('x'))).alias('ln(A_2)'),\n",
    "                (-(r + pl.col('x')) * np.log(alpha + pl.col('T'))).alias('ln(A_3)'),\n",
    "                (pl.when(pl.col('x') > 0)\n",
    "                .then(np.log(a) - np.log(b + pl.col('x') - 1) - (r + pl.col('x')) * np.log(alpha + pl.col('t_x')))\n",
    "                .otherwise(0)        \n",
    "                ).alias('ln(A_4)')\n",
    "            ).with_columns(\n",
    "                (pl.col('ln(A_1)') + pl.col('ln(A_2)') + np.log(np.exp(pl.col('ln(A_3)')) + (pl.col('x') > 0) * np.exp(pl.col('ln(A_4)')))).alias('ln(.)')\n",
    "            ).select(pl.col('ln(.)').sum())\n",
    "            .collect().item(0,0)\n",
    "        )\n",
    "    bnds = [(0, np.inf) for _ in range(4)]\n",
    "    return minimize(log_likelihood, x0=list(guess.values()), bounds=bnds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 9582.44760081516\n",
       "        x: [ 2.420e-01  4.394e+00  8.272e-01  2.559e+00]\n",
       "      nit: 18\n",
       "      jac: [-5.275e-02 -1.484e-01  1.306e-01  2.123e-01]\n",
       "     nfev: 100\n",
       "     njev: 20\n",
       " hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgnbd_est(rfm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0s/z9xp988n3j78zfjwg3y616x00000gn/T/ipykernel_91165/1694035003.py:10: RuntimeWarning: invalid value encountered in log\n",
      "  np.log(a) - np.log(b + rfm_data[:,0] - 1) - (r + rfm_data[:,0]) * np.log(alpha + rfm_data[:,1]),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 9582.447599720595\n",
       "        x: [ 2.420e-01  4.394e+00  8.272e-01  2.559e+00]\n",
       "      nit: 18\n",
       "      jac: [-5.148e-02 -1.481e-01  1.308e-01  2.126e-01]\n",
       "     nfev: 100\n",
       "     njev: 20\n",
       " hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bgnbd_est(rfm_data, guess={'r': 0.1, 'alpha': 0.1, 'a': 0.1, 'b':0.1}):\n",
    "    \n",
    "    def log_likelihood(x):\n",
    "        r, alpha, a, b = x\n",
    "\n",
    "        ln_A_1 = gammaln(rfm_data[:,0] + r) - gammaln(r) + r * np.log(alpha)\n",
    "        ln_A_2 = gammaln(a + b) + gammaln(b + rfm_data[:,0]) - gammaln(b) - gammaln(a + b + rfm_data[:,0])\n",
    "        ln_A_3 = -(r + rfm_data[:,0]) * np.log(alpha + rfm_data[:,2])\n",
    "        ln_A_4 = np.where(rfm_data[:,0] > 0, \n",
    "                          np.log(a) - np.log(b + rfm_data[:,0] - 1) - (r + rfm_data[:,0]) * np.log(alpha + rfm_data[:,1]),\n",
    "                          0)\n",
    "        return -np.sum(ln_A_1 + ln_A_2 + np.log(np.exp(ln_A_3) + (rfm_data[:,0] > 0) * np.exp(ln_A_4)))\n",
    "    \n",
    "    bnds = [(0, np.inf) for _ in range(4)]\n",
    "    return minimize(log_likelihood, x0=list(guess.values()), bounds=bnds)\n",
    "\n",
    "bgnbd_est(rfm_data.select('x', 't_x', 'T').collect().to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
