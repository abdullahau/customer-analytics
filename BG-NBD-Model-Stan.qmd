---
title: BG/NBD Model - Stan Implementation
author: Abdullah Mahmood
date: last-modified
format:
  html:
    theme: cosmo
    highlight-style: atom-one
    mainfont: Palatino
    fontcolor: black
    monobackgroundcolor: white
    monofont: Menlo, Lucida Console, Liberation Mono, DejaVu Sans Mono, Bitstream Vera Sans Mono, Courier New, monospace
    fontsize: 13pt
    linestretch: 1.4
    number-sections: true
    number-depth: 4
    toc: true
    toc-location: right
    toc-depth: 4
    code-fold: false
    code-copy: true
    cap-location: bottom
    format-links: false
    embed-resources: true
    anchor-sections: true
    html-math-method:
      method: mathjax
      url: https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js
editor: source
jupyter:
  jupytext:
    formats: ipynb,qmd
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.16.7
  kernelspec:
    display_name: main
    language: python
    name: main
---

### Imports

#### Packages

```{python}
import polars as pl
import numpy as np
from scipy.optimize import minimize
from utils import CDNOW, Stan, StanQuap
```

#### Data

```{python}
calib_p = 273 # 39 week calibration period

data = CDNOW(master=False, calib_p=calib_p)

rfm_data = data.rfm_summary().select("P1X", "t_x", "T").collect().to_numpy()
p1x, t_x, T = rfm_data[:, 0], rfm_data[:, 1], rfm_data[:, 2]
```

## Analytical MLE

### Standard SciPy Implementation

```{python}
from scipy.special import gammaln, hyp2f1, gamma, factorial

def bgnbd_ll(x, p1x, t_x, T):
    r, alpha, a, b = x

    # Logarithm calculations with numerical stability
    log_alpha = np.log(np.clip(alpha, 1e-10, None))  # Avoid log(0) by clipping to a small value
    log_alpha_t_x = np.log(np.clip(alpha + t_x, 1e-10, None))

    # Components of the log-likelihood
    D_1 = (
        gammaln(r + p1x)
        - gammaln(r)
        + gammaln(a + b)
        + gammaln(b + p1x)
        - gammaln(b)
        - gammaln(a + b + p1x)
    )
    D_2 = r * log_alpha - (r + p1x) * log_alpha_t_x
    C_3 = ((alpha + t_x) / (alpha + T)) ** (r + p1x)
    C_4 = a / (b + p1x - 1)

    # Handle cases where p1x > 0 and apply log to valid values
    log_term = np.log(np.clip(C_3 + C_4, 1e-10, None))
    result = D_1 + D_2 + np.where(p1x > 0, log_term, np.log(np.clip(C_3, 1e-10, None)))

    return -np.sum(result)

def bgnbd_est():
    guess={'r': 0.01, 'alpha': 0.01, 'a': 0.01, 'b': 0.01}
    # Bounds for the optimization
    bnds = [(1e-6, np.inf) for _ in range(4)]

    # Optimization using minimize
    return minimize(
        bgnbd_ll,
        x0=list(guess.values()),
        method="BFGS",
        args=(p1x, t_x, T)
    )

result = bgnbd_est()
r, alpha, a, b = result.x
ll = result.fun

print(
f"""r = {r:0.4f}
α = {alpha:0.4f}
a = {a:0.4f}
b = {b:0.4f}
Log-Likelihood = {-ll:0.4f}"""
)

index = index=["r", "α", "a", "b"]
params = result.x
var_mat = result.hess_inv
se = np.sqrt(np.diag(var_mat))
plo = params - 1.96 * se
phi = params + 1.96 * se
pl.DataFrame(
    {
        "Parameter": index,
        "Coef": params,
        "SE (Coef)": se,
        "5.5%": plo,
        "94.5%": phi,
    }
)
```

### **Cameron Davidson-Pilon's `lifetimes`** Implementation

Source: [BetaGeoFitter](https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/fitters/beta_geo_fitter.py), [fit function](https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/fitters/__init__.py)

```{python}
import autograd.numpy as np
from autograd.scipy.special import gammaln, beta, gamma
from autograd import value_and_grad, hessian

def negative_log_likelihood(log_params, freq, rec, T):
    params = np.exp(log_params)
    r, alpha, a, b = params

    A_1 = gammaln(r + freq) - gammaln(r) + r * np.log(alpha)
    A_2 = gammaln(a + b) + gammaln(b + freq) - gammaln(b) - gammaln(a + b + freq)
    A_3 = -(r + freq) * np.log(alpha + T)
    A_4 = np.log(a) - np.log(b + np.maximum(freq, 1) - 1) - (r + freq) * np.log(rec + alpha)

    max_A_3_A_4 = np.maximum(A_3, A_4)

    ll = (A_1 + A_2 + np.log(np.exp(A_3 - max_A_3_A_4) + np.exp(A_4 - max_A_3_A_4) * (freq > 0)) + max_A_3_A_4)

    return -ll.sum()

def BetaGeoFitter(guess={'r': 0.1, 'alpha': 0.1, 'a': 0.0, 'b': 0.1}):
    
    # Bounds for the optimization
    # bnds = [(1e-6, np.inf) for _ in range(4)]

    # Optimization using minimize
    return minimize(
        value_and_grad(negative_log_likelihood),
        jac=True,
        method=None,
        args=(p1x, t_x, T),
        tol=1e-7, 
        x0=list(guess.values()),
        options={'disp': True}
    )

result = BetaGeoFitter()
r, alpha, a, b = np.exp(result.x)
ll = result.fun

print(
f"""r = {r:0.4f}
α = {alpha:0.4f}
a = {a:0.4f}
b = {b:0.4f}
Log-Likelihood = {-ll:0.4f}"""
)

index = index=["r", "α", "a", "b"]
params = np.exp(result.x)
hessian_mat = hessian(negative_log_likelihood)(result.x, p1x, t_x, T)
var_mat = (params ** 2) * np.linalg.inv(hessian_mat) # Variance-Covariance Matrix
se = np.sqrt(np.diag(var_mat))  # Standard Error
plo = params - 1.96 * se
phi = params + 1.96 * se
pl.DataFrame(
    {
        "Parameter": index,
        "Coef": params,
        "SE (Coef)": se,
        "5.5%": plo,
        "94.5%": phi,
    }
)
```

## Stan Model

```{python}
stan_code = '''
data {
  int<lower=0> N;             // Number of customers
  array[N] int<lower=0> X;          // Number of transactions per customer
  vector<lower=0>[N] T;       // Total observation time per customer
  vector<lower=0>[N] t_x;     // Time of last transaction (0 if X=0)
}

parameters {
  real<lower=0> r;            // Gamma shape for transaction rate (λ)
  real<lower=0> alpha;        // Gamma scale for λ
  real<lower=0> a;            // Beta shape 1 for dropout probability (p)
  real<lower=0> b;            // Beta shape 2 for p
}

model {
  // Weakly informative priors (adjust based on domain knowledge)
  r ~ gamma(1, 0.1);
  alpha ~ gamma(1, 0.1);
  a ~ gamma(1, 0.1);
  b ~ gamma(1, 0.1);

  for (i in 1:N) {
    if (X[i] == 0) {
      // Likelihood for X=0: (alpha/(alpha + T[i]))^r
      real log_term = r * (log(alpha) - log(alpha + T[i]));
      target += log_term;
    } else {
      // Term 1: B(a, b + X[i])/B(a, b) * gamma(r + X[i])/gamma(r) * (alpha/(alpha + T[i]))^{r + X[i]}
      real log_term1 = lbeta(a, b + X[i]) - lbeta(a, b)
                      + lgamma(r + X[i]) - lgamma(r)
                      + r * log(alpha) - (r + X[i]) * log(alpha + T[i]);

      // Term 2: B(a + 1, b + X[i] - 1)/B(a, b) * gamma(r + X[i])/gamma(r) * (alpha/(alpha + t_x[i]))^{r + X[i]}
      real log_term2 = lbeta(a + 1, b + X[i] - 1) - lbeta(a, b)
                      + lgamma(r + X[i]) - lgamma(r)
                      + r * log(alpha) - (r + X[i]) * log(alpha + t_x[i]);

      // Sum both terms (log-space)
      target += log_sum_exp(log_term1, log_term2);
    }
  }
}
'''

d = rfm_data.select("P1X", "t_x", "T").collect()

inits = {'r': 0.01, 'alpha': 0.01, 'a': 0.01, 'b': 0.01}

data = {
    'N': len(d),
    'X': d.select('P1X').to_numpy().flatten().tolist(),
    'T': d.select('T').to_numpy().flatten().tolist(),
    't_x': d.select('t_x').to_numpy().flatten().tolist()
}

stan_model = StanQuap('stan_models/bg-nbd', stan_code, data=data, algorithm='LBFGS', jacobian=False, inits=inits)
stan_model.opt_model.optimized_params_pd
```

```{python}
theta_unc = stan_model.bs_model.param_unconstrain(stan_model.opt_model.optimized_params_np[1:])
stan_model.bs_model.log_density_hessian(theta_unc, jacobian=False)
```