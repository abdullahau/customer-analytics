---
title: BG/NBD Model - Stan Implementation
author: Abdullah Mahmood
date: last-modified
format:
  html:
    theme: cosmo
    highlight-style: atom-one
    mainfont: Palatino
    fontcolor: black
    monobackgroundcolor: white
    monofont: Menlo, Lucida Console, Liberation Mono, DejaVu Sans Mono, Bitstream Vera Sans Mono, Courier New, monospace
    fontsize: 13pt
    linestretch: 1.4
    number-sections: true
    number-depth: 4
    toc: true
    toc-location: right
    toc-depth: 4
    code-fold: false
    code-copy: true
    cap-location: bottom
    format-links: false
    embed-resources: true
    anchor-sections: true
    html-math-method:
      method: mathjax
      url: https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js
editor: source
jupyter:
  jupytext:
    formats: ipynb,qmd
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.16.7
  kernelspec:
    display_name: main
    language: python
    name: main
---

### Imports

#### Packages

```{python}
import polars as pl
import numpy as np
from scipy.optimize import minimize
from utils import CDNOW, Stan, StanQuap
```

#### Data

```{python}
calib_p = 273 # 39 week calibration period

data = CDNOW(master=False, calib_p=calib_p)

rfm_data = data.rfm_summary().select("P1X", "t_x", "T").collect().to_numpy()
p1x, t_x, T = rfm_data[:, 0], rfm_data[:, 1], rfm_data[:, 2]
```

## Analytical MLE

### Standard SciPy Implementation

```{python}
import numpy as np
from scipy.special import gammaln, hyp2f1, gamma, factorial

def bgnbd_ll(x, p1x, t_x, T):
    r, alpha, a, b = x

    # Logarithm calculations with numerical stability
    log_alpha = np.log(np.clip(alpha, 1e-10, None))  # Avoid log(0) by clipping to a small value
    log_alpha_t_x = np.log(np.clip(alpha + t_x, 1e-10, None))

    # Components of the log-likelihood
    D_1 = (
        gammaln(r + p1x)
        - gammaln(r)
        + gammaln(a + b)
        + gammaln(b + p1x)
        - gammaln(b)
        - gammaln(a + b + p1x)
    )
    D_2 = r * log_alpha - (r + p1x) * log_alpha_t_x
    C_3 = ((alpha + t_x) / (alpha + T)) ** (r + p1x)
    C_4 = a / (b + p1x - 1)

    # Handle cases where p1x > 0 and apply log to valid values
    log_term = np.log(np.clip(C_3 + C_4, 1e-10, None))
    result = D_1 + D_2 + np.where(p1x > 0, log_term, np.log(np.clip(C_3, 1e-10, None)))

    return -np.sum(result)

def bgnbd_est():
    guess={'r': 0.01, 'alpha': 0.01, 'a': 0.01, 'b': 0.01}
    # Bounds for the optimization
    bnds = [(1e-6, np.inf) for _ in range(4)]

    # Optimization using minimize
    return minimize(
        bgnbd_ll,
        x0=list(guess.values()),
        method="BFGS",
        args=(p1x, t_x, T)
    )

result = bgnbd_est()
r, alpha, a, b = result.x
ll = result.fun

print(
f"""r = {r:0.4f}
α = {alpha:0.4f}
a = {a:0.4f}
b = {b:0.4f}
Log-Likelihood = {-ll:0.4f}"""
)

index = index=["r", "α", "a", "b"]
params = result.x
var_mat = result.hess_inv
se = np.sqrt(np.diag(var_mat))
plo = params - 1.96 * se
phi = params + 1.96 * se
pl.DataFrame(
    {
        "Parameter": index,
        "Coef": params,
        "SE (Coef)": se,
        "5.5%": plo,
        "94.5%": phi,
    }
)
```

### **Cameron Davidson-Pilon's `lifetimes`** Implementation

Source: [BetaGeoFitter](https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/fitters/beta_geo_fitter.py), [fit function](https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/fitters/__init__.py)

```{python}
import autograd.numpy as np
from autograd.scipy.special import gammaln, beta, gamma
from autograd import value_and_grad, hessian

def negative_log_likelihood(log_params, freq, rec, T):
    params = np.exp(log_params)
    r, alpha, a, b = params

    A_1 = gammaln(r + freq) - gammaln(r) + r * np.log(alpha)
    A_2 = gammaln(a + b) + gammaln(b + freq) - gammaln(b) - gammaln(a + b + freq)
    A_3 = -(r + freq) * np.log(alpha + T)
    A_4 = np.log(a) - np.log(b + np.maximum(freq, 1) - 1) - (r + freq) * np.log(rec + alpha)

    max_A_3_A_4 = np.maximum(A_3, A_4)

    ll = (A_1 + A_2 + np.log(np.exp(A_3 - max_A_3_A_4) + np.exp(A_4 - max_A_3_A_4) * (freq > 0)) + max_A_3_A_4)

    return -ll.sum()

def BetaGeoFitter(guess={'r': 0.1, 'alpha': 0.1, 'a': 0.0, 'b': 0.1}):
    
    # Bounds for the optimization
    # bnds = [(1e-6, np.inf) for _ in range(4)]

    # Optimization using minimize
    return minimize(
        value_and_grad(negative_log_likelihood),
        jac=True,
        method=None,
        args=(p1x, t_x, T),
        tol=1e-7, 
        x0=list(guess.values()),
        options={'disp': True}
    )

result = BetaGeoFitter()
r, alpha, a, b = np.exp(result.x)
ll = result.fun

print(
f"""r = {r:0.4f}
α = {alpha:0.4f}
a = {a:0.4f}
b = {b:0.4f}
Log-Likelihood = {-ll:0.4f}"""
)

index = index=["r", "α", "a", "b"]
params = np.exp(result.x)
hessian_mat = hessian(negative_log_likelihood)(result.x, p1x, t_x, T)
var_mat = (params ** 2) * np.linalg.inv(hessian_mat) # Variance-Covariance Matrix
se = np.sqrt(np.diag(var_mat))  # Standard Error
plo = params - 1.96 * se
phi = params + 1.96 * se
pl.DataFrame(
    {
        "Parameter": index,
        "Coef": params,
        "SE (Coef)": se,
        "5.5%": plo,
        "94.5%": phi,
    }
)
```

## Stan Model

```{python}
stan_code = '''
data {
    int<lower=0> N;                // Number of customers
    array[N] int<lower=0> X;       // Number of transactions per customer
    vector<lower=0>[N] t_x;        // Time of last transaction (0 if X=0)  
    vector<lower=0>[N] T;          // Total observation time per customer (Time Since first trial)
}

parameters {
    real<lower=0> r;                   // gamma shape (r)
    real<lower=0> alpha;               // gamma scale (alpha)
    real<lower=0, upper=5> a;          // beta shape 1 (a)
    real<lower=0, upper=5> b;          // beta shape 2 (b)
}

model {
  // Weakly informative priors
  r ~ weibull(2, 1);
  alpha ~ weibull(2, 10);
  a ~ uniform(0, 5);
  b ~ uniform(0, 5);

  for (n in 1:N) {
    int x = X[n];
    real tx = Tx[n];
    real t = T[n];

    if (x == 0) {
      // Likelihood for X=0: (alpha/(alpha + t))^r
      target += r * (log(alpha) - log(alpha + t));
    } else {
      // Term 1: B(a, b + x)/B(a, b) * Γ(r + x)/Γ(r) * (alpha/(alpha + t))^(r + x)
      real beta_term1 = lbeta(a, b + x) - lbeta(a, b);
      real gamma_term = lgamma(r + x) - lgamma(r);
      real term1 = gamma_term + beta_term1 + r * log(alpha) - (r + x) * log(alpha + t);

      // Term 2: B(a + 1, b + x - 1)/B(a, b) * Γ(r + x)/Γ(r) * (alpha/(alpha + tx))^(r + x)
      real beta_term2 = lbeta(a + 1, b + x - 1) - lbeta(a, b);
      real term2 = gamma_term + beta_term2 + r * log(alpha) - (r + x) * log(alpha + tx);

      // Log-sum-exp for numerical stability
      target += log_sum_exp(term1, term2);
    }
  }
}
'''
data = {
    'N': len(rfm_data),
    'X': p1x.flatten().astype(int).tolist(),
    't_x': t_x.flatten().tolist(),
    'T': T.flatten().tolist()
}

stan_model = StanQuap('stan_models/bg-nbd', stan_code, data=data, algorithm='BFGS', jacobian=False, tol_rel_grad=1e-7)
stan_model.precis(eps=1e-6)

index = index=["r", "α", "a", "b"]
params = np.array(list(stan_model.opt_model.stan_variables().values()))
var_mat = var_mar = stan_model.vcov_matrix() # Variance-Covariance Matrix
se = np.sqrt(np.diag(var_mat))  # Standard Error
plo = params - 1.96 * se
phi = params + 1.96 * se
pl.DataFrame(
    {
        "Parameter": index,
        "Coef": params,
        "SE (Coef)": se,
        "5.5%": plo,
        "94.5%": phi,
    }
)
```

```{python}
stan_model.precis(eps=1e-6)
stan_model.opt_model.optimized_params_pd
```

```{python}
x = [stan_model.opt_model.optimized_params_pd['r'][0], 
 stan_model.opt_model.optimized_params_pd['alpha'][0], 
stan_model.opt_model.optimized_params_pd['a'][0],
stan_model.opt_model.optimized_params_pd['b'][0]]

bgnbd_ll(x, p1x, t_x, T)
```

```{python}
x = np.array([stan_model.opt_model.optimized_params_pd['r'][0], 
 stan_model.opt_model.optimized_params_pd['alpha'][0], 
stan_model.opt_model.optimized_params_pd['a'][0],
stan_model.opt_model.optimized_params_pd['b'][0]])

negative_log_likelihood(np.log(x), p1x, t_x, T)
```