{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from scipy.special import gammaln, hyp2f1\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from IPython.display import display_markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDNOW = (\n",
    "    pl.scan_csv(source='data/CDNOW/CDNOW_sample.csv',\n",
    "                has_header=False,\n",
    "                separator=',',\n",
    "                schema={'CustID': pl.Int32,\n",
    "                        'ID': pl.Int32,\n",
    "                        'Date': pl.String,\n",
    "                        'Quant': pl.Int16,\n",
    "                        'Spend': pl.Float64})\n",
    "    .with_columns(pl.col('Date').str.to_date(\"%Y%m%d\"))\n",
    "    .with_columns((pl.col('Date') - pl.date(1996,12,31)).dt.total_days().cast(pl.UInt16).alias('PurchDay'))\n",
    "    .with_columns((pl.col('Spend')*100).round(0).cast(pl.Int64).alias('Spend Scaled'))\n",
    "    .group_by('ID', 'Date')\n",
    "    .agg(pl.col('*').exclude('PurchDay').sum(), pl.col('PurchDay').max())\n",
    "    .sort('ID', 'Date')\n",
    "    .with_columns((pl.col(\"ID\").cum_count().over(\"ID\") - 1).cast(pl.UInt16).alias(\"DoR\"))      \n",
    "    .drop('CustID')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "calwk = 273 # 39 week calibration period\n",
    "\n",
    "# The number of repeat transactions made by each customer in each period\n",
    "freq_x = (\n",
    "    CDNOW\n",
    "    .group_by('ID', maintain_order=True)\n",
    "    .agg(\n",
    "        pl.col('PurchDay')\n",
    "        .filter((pl.col('PurchDay') <= calwk) & (pl.col('DoR') > 0))\n",
    "        .count()\n",
    "        .alias('P1X'), # Period 1: Calibration Period\n",
    "\n",
    "        pl.col('PurchDay')\n",
    "        .filter((pl.col('PurchDay') > calwk) & (pl.col('DoR') > 0))\n",
    "        .count()\n",
    "        .alias('P2X')  # Period 2: Longitudinal Holdout Period      \n",
    "    )\n",
    ")\n",
    "\n",
    "# The number of CDs purchased and total spend across these repeat transactions\n",
    "pSpendQuant = (\n",
    "    CDNOW\n",
    "    .join(freq_x, on='ID', how='left')\n",
    "    .group_by('ID', maintain_order=True)\n",
    "    .agg(\n",
    "        \n",
    "        pl.col('Spend Scaled')\n",
    "        .filter((pl.col('DoR') > 0) & (pl.col('DoR') <= pl.col('P1X')) & (pl.col('P1X') != 0))\n",
    "        .sum()\n",
    "        .alias('P1X Spend'),\n",
    "        \n",
    "        pl.col('Quant')\n",
    "        .filter((pl.col('DoR') > 0) & (pl.col('DoR') <= pl.col('P1X')) & (pl.col('P1X') != 0))\n",
    "        .sum()\n",
    "        .alias('P1X Quant'),        \n",
    "        \n",
    "        pl.col('Spend Scaled')\n",
    "        .filter((pl.col('DoR') > 0) & (pl.col('DoR') > pl.col('P1X')))\n",
    "        .sum()\n",
    "        .alias('P2X Spend'),\n",
    "        \n",
    "        pl.col('Quant')\n",
    "        .filter((pl.col('DoR') > 0) & (pl.col('DoR') > pl.col('P1X')))\n",
    "        .sum()\n",
    "        .alias('P2X Quant')                \n",
    "    )\n",
    ")\n",
    "\n",
    "# The average spend per repeat transaction\n",
    "m_x = (\n",
    "    pSpendQuant\n",
    "    .join(freq_x, on='ID', how='left')\n",
    "    .with_columns(\n",
    "        (pl.col('P1X Spend') / pl.col('P1X')).alias('m_x_calib'),\n",
    "        (pl.col('P2X Spend') / pl.col('P2X')).alias('m_x_valid')\n",
    "    ).fill_nan(0)\n",
    ")\n",
    "\n",
    "# time of last calibration period repeat purchase (in weeks) - Recency\n",
    "ttlrp = (\n",
    "    CDNOW\n",
    "    .join(freq_x, on='ID', how='left')\n",
    "    .with_columns(\n",
    "        pl.col('PurchDay').filter(pl.col('DoR') == 0)\n",
    "        .first()\n",
    "        .over('ID')\n",
    "        .alias('Trial Day')\n",
    "    )\n",
    "    .group_by('ID', maintain_order=True)\n",
    "    .agg(\n",
    "        pl.col('PurchDay', 'Trial Day')\n",
    "        .filter(pl.col('DoR') <= pl.col('P1X'))\n",
    "        .max()\n",
    "        # .alias('LastPurch')\n",
    "    )\n",
    "    .with_columns(\n",
    "        # effective calibration period (in weeks)\n",
    "        ((pl.col('PurchDay') - pl.col('Trial Day')) / 7).alias('t_x'), # Time to Last Repeat Purchase - Recency\n",
    "        ((calwk - pl.col('Trial Day'))/7).alias('T')\n",
    "    )\n",
    "    .drop('PurchDay', 'Trial Day')\n",
    ")\n",
    "\n",
    "rfm_data = (\n",
    "    m_x\n",
    "    .join(other=ttlrp, on=\"ID\", how=\"left\")\n",
    "    .rename({'P1X': 'x'})\n",
    "    .select('ID', 'x', 't_x', 'T')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdullah-Mahmood\\AppData\\Local\\Temp\\ipykernel_21424\\3747063264.py:10: RuntimeWarning: invalid value encountered in log\n",
      "  np.log(a) - np.log(b + rfm_data[:,0] - 1) - (r + rfm_data[:,0]) * np.log(alpha + rfm_data[:,1]),\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "$r$ = 0.2426\n",
       "\n",
       "$\\alpha$ = 4.4136\n",
       "\n",
       "$a$ = 0.7929\n",
       "\n",
       "$b$ = 2.4259\n",
       "\n",
       "Log-Likelihood = -9582.4292"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bgnbd_est(rfm_data, guess={'r': 0.01, 'alpha': 0.01, 'a': 0.01, 'b':0.01}):\n",
    "    \n",
    "    def log_likelihood(x):\n",
    "        r, alpha, a, b = x\n",
    "\n",
    "        ln_A_1 = gammaln(rfm_data[:,0] + r) - gammaln(r) + r * np.log(alpha)\n",
    "        ln_A_2 = gammaln(a + b) + gammaln(b + rfm_data[:,0]) - gammaln(b) - gammaln(a + b + rfm_data[:,0])\n",
    "        ln_A_3 = -(r + rfm_data[:,0]) * np.log(alpha + rfm_data[:,2])\n",
    "        ln_A_4 = np.where(rfm_data[:,0] > 0, \n",
    "                          np.log(a) - np.log(b + rfm_data[:,0] - 1) - (r + rfm_data[:,0]) * np.log(alpha + rfm_data[:,1]),\n",
    "                          0)\n",
    "        return -np.sum(ln_A_1 + ln_A_2 + np.log(np.exp(ln_A_3) + (rfm_data[:,0] > 0) * np.exp(ln_A_4)))\n",
    "    \n",
    "    bnds = [(0, np.inf) for _ in range(4)]\n",
    "    return minimize(log_likelihood, x0=list(guess.values()), bounds=bnds)\n",
    "\n",
    "result = bgnbd_est(rfm_data.select('x', 't_x', 'T').collect().to_numpy())\n",
    "r, alpha, a, b = result.x\n",
    "ll = result.fun\n",
    "\n",
    "display_markdown(f'''$r$ = {r:0.4f}\n",
    "\n",
    "$\\\\alpha$ = {alpha:0.4f}\n",
    "\n",
    "$a$ = {a:0.4f}\n",
    "\n",
    "$b$ = {b:0.4f}\n",
    "\n",
    "Log-Likelihood = {-ll:0.4f}''', raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizon = (calwk * 2) // 7\n",
    "\n",
    "t = np.arange(1/7, forecast_horizon, 1/7)\n",
    "z = t / (alpha + t)\n",
    "h2f1 = hyp2f1(r, b, (a + b - 1), z)\n",
    "E_X_t = (a + b - 1) / (a - 1) * (1 - (alpha / (alpha + t))**r * h2f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00781366, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.01555185, 0.00781366, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.85180813, 1.84770019, 1.84770019, ..., 1.67810192, 1.67360794,\n",
       "        1.67135695],\n",
       "       [1.8538589 , 1.84975523, 1.84770019, ..., 1.68034491, 1.67585626,\n",
       "        1.67360794],\n",
       "       [1.8538589 , 1.85180813, 1.84975523, ..., 1.68034491, 1.67810192,\n",
       "        1.67585626]], shape=(546, 84))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tffr = (\n",
    "    ttlrp\n",
    "    .with_columns((39 - pl.col('T')).alias('Time of First Repeat'))\n",
    "    .group_by('Time of First Repeat').agg(pl.len().alias('Count'))\n",
    "    .sort('Time of First Repeat')\n",
    "    .collect()\n",
    "    .to_numpy()\n",
    ")\n",
    "\n",
    "num_triers = tffr[:, 1]\n",
    "trial_week = tffr[:, 0]\n",
    "time_trial_week = np.arange(1/7, np.max(trial_week), 1/7)\n",
    "\n",
    "a, _ = np.meshgrid(time_trial_week,t)\n",
    "\n",
    "test = ((t.reshape(-1,1) - a) * 7).astype(np.int16)\n",
    "\n",
    "index = np.where(test < 0, 0, test) - 1\n",
    "\n",
    "np.tril(E_X_t[np.clip(index, 0, E_X_t.shape[0] - 1)], k=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
